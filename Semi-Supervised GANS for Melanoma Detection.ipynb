{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20da7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D,Conv2DTranspose,Input,Dense,Flatten,BatchNormalization,LeakyReLU,Dropout,Reshape\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08e5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2143ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a243c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"F:/Code/jaskirat`s Sir/Semi-Supervised-Learning-for-Healthcare/MelanomaDetection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b050e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_datagen = ImageDataGenerator(featurewise_center=True , horizontal_flip=True ,vertical_flip=True ,\n",
    "                                    rescale=1/255, brightness_range=(.5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cc1c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7018 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = unlabeled_datagen.flow_from_directory(directory=root_dir,\n",
    "                                                       classes = [\"unlabeled\"],\n",
    "                                                       target_size = (32,32),\n",
    "                                                       batch_size=256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebdc5223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c4e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    dis = Sequential(name = \"Discriminator\")\n",
    "    \n",
    "    dis.add(Conv2D(filters=64,kernel_size=4,strides=2,padding=\"same\",input_shape=(32,32,3),use_bias=False))\n",
    "    dis.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    dis.add(Conv2D(filters=128,kernel_size=4,strides=2,padding=\"same\",use_bias=False))\n",
    "    dis.add(BatchNormalization())\n",
    "    dis.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    dis.add(Conv2D(filters=256,kernel_size=4,strides=2,padding=\"same\",use_bias=False))\n",
    "    dis.add(BatchNormalization())\n",
    "    dis.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    dis.add(Flatten())\n",
    "    dis.add(Dropout(0.4))\n",
    "    \n",
    "    dis.add(Dense(units = 1, activation = \"sigmoid\"  ))\n",
    "    return dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd472813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    noise = 100\n",
    "    gen= Sequential(name= \"Generator\")\n",
    "    \n",
    "    gen.add(Input(shape=(noise,)))\n",
    "    gen.add(Dense(units = 4*4*100 ,activation = \"linear\"))\n",
    "    gen.add(Reshape((4,4,100)))\n",
    "    \n",
    "    gen.add(Conv2DTranspose(filters=256,kernel_size=4,strides=1,padding=\"same\",use_bias=False))\n",
    "    gen.add(BatchNormalization())\n",
    "    gen.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    gen.add(Conv2DTranspose(filters = 128,kernel_size=4, strides = 2 ,padding =\"same\", use_bias = False))\n",
    "    gen.add(BatchNormalization())\n",
    "    gen.add(LeakyReLU(alpha = 0.2))\n",
    "            \n",
    "    gen.add(Conv2DTranspose(filters = 64 , kernel_size = 4, strides =2 ,padding =\"same\" ,use_bias =False))\n",
    "    gen.add(BatchNormalization())\n",
    "    gen.add(LeakyReLU(alpha =0.2))\n",
    "            \n",
    "    gen.add(Conv2DTranspose(filters = 3 ,kernel_size =4, strides =2 ,padding =\"same\" ,use_bias =False))\n",
    "    \n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a55d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34b82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 64)        3072      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 128)         131072    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 128)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 664,065\n",
      "Trainable params: 663,297\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bcffdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model=D,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dafce00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2024f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 1600)              161600    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 100)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 4, 4, 256)        409600    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 128)        524288    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 64)       131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 3)        3072      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,231,424\n",
      "Trainable params: 1,230,528\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "427007b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model=G,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea6adf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0494a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = G(random_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43d7124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ea0477ab50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW4UlEQVR4nO2dXahtV3XHf2N/nHvTJKJp2nCJsVEbKEE0yiVYCGItSipCFIootORBvFIMVLAPIYWa9qkWP/DJcq3BWKya+lGDSDUGIfZFTWxMomk1SkTDNVdRSTTm3rP3Hn3YK825xz3+55x19tn76Pz/4HL3WXPPOceaa/3XWnuONcaMzMQY89vPYN0GGGNWg8VuTCNY7MY0gsVuTCNY7MY0gsVuTCOM9lM5Iq4F3gcMgX/JzH/c4fv28xlzwGRmLNoeff3sETEEvg28Evgh8DXgjZn5LVFnuWJfuEsdvqzsHvF8F7O6rM8Qq0dJ0VXvY11VWyyHro5oT+5z752rDBFlysZC7Pt5jL8aeCgzv5eZZ4GPAdftoz1jzAGyH7FfCvxgy98/7LYZYw4h+/rNvhsi4gRw4qD7McZo9iP2R4DLtvz97G7bOWTmSeAkeILOmHWyn8f4rwFXRMRzI2IDeANw+3LMMsYsm9539sycRMQNwOeZu95uycxv9rakz8xjCvNjsvf2djRk7w2GaE46QkZ1xZjU1+hgunD7QOzXRMwUD8S+Le7paUsWMZMPdz0HS86sLy5UXih9KorSgbBxNqyrFWM8yz5T+DW9XW+9OlOP8b3cDBb7r5X1EbswY7hksUu/1gGIfVCIfSb2S3vQRGcjYeOkh9h7+esOxvVmjPkNwmI3phEsdmMawWI3phEsdmMa4cDfoNstfSbjR2LGXc0wy72e9PBOiCn37BuRI2afU8yD58bi7TMxIAMx+FM15b5R3ysGZxfPJM9UBMpYjJWyQ0xaz5Q7rKxTl43E+THpGbkyGxU7IE/iveM7uzGNYLEb0wgWuzGNYLEb0wgWuzGNsPp346sJSxXMUExWqiuVfm97yai0Tmq/RMXZVFUUe1cdzoNIwyRZ3KF611711Tdl1bBodNozhZSqlqI0e73nXr9Pr85wvxtvTONY7MY0gsVuTCNY7MY0gsVuTCNY7MY0wuFJS9WHfp4JQlziZNKkwntyECMYR+qy3KzLBoWNfV1X0nWoUq5VZUWgDkCcrcvUoZ4oG6v+RJooRarIIHHMBmfqsjI9nfIfV2nLJmnXmzGtY7Eb0wgWuzGNYLEb0wgWuzGNYLEb0wj7cr1FxMPA48ydBJPMPL7D98vO+nnRVK3a2RSiXvZK/FVfM8fCMbcplwsSfhwZ9Va4ZIbCXzc9ry7jV6JM3SuqqDdhhjjSfdbpgToSLfqutiJ3YFyXyRWKqnHsF7tZud6WkXDyTzLzJ0toxxhzgPgx3phG2K/YE/hCRNwTESeWYZAx5mDY72P8NZn5SET8PnBHRPxPZt619QvdRcAXAmPWzNLejY+Im4FfZOa7xHc8QbcFT9BtM8MTdNsb3I1Jv97cst+Nj4jzI+LCpz4DrwIe6NueMeZg2c9j/CXAp2MeFjUC/i0z/7NvY9M+t/Yj4sonIqgY11fZoYiGGswW9zcZ1ncJ+ZwgzB+LMKlNtTxR8bAwUX1FffeejcU9Vdwcq7u0TPQoGAn7B7Paxklh5FQ90IobtAxxPCKensRYjarzSqzLFZuLDVHm9RZ7Zn4PeFHf+saY1WLXmzGNYLEb0wgWuzGNYLEb0wgWuzGNcGgSTg6Fh6d2kwh/nXzxRFzjhButcpXpZcP6LSqm1oFT64YNioyOM+WLHAobxYs/48L9A7BZ+HmGwhep3K+jcW3j5Ml6PCp3k351Sri8xHikek9HnN+DQZEVc1ofM9WVE04a0zgWuzGNYLEb0wgWuzGNYLEb0wiHZja+DxtiivOs6Gok1jSalOsWUQdIiPgHtXySHHoVjCH6K4dE9DU4Wl/zZ5t7905IfqcuGj1Rlw3ETP1EmDgrxnFDOCfODkVnavkndetUx7os27tXIGeejTemeSx2YxrBYjemESx2YxrBYjemESx2YxrhN9r1prNq1V0NemYxnRbXxoEISxgJH9pZ6UOr3T86SGZxm/2y90L09B1WtWZDccymddmQJ+t6o3o8ppPCRnUqVhl6gT4ZdefUoTdR1esZdGPXmzGNY7Eb0wgWuzGNYLEb0wgWuzGNYLEb0wg7ut4i4hbgNcDpzHxBt+0i4OPA5cDDwOsz82c7dqZcb/KyUyzON6j9D6mSjCkPiRyOwoEl1iaSjhqxFtJU5cKbiB24sNiBx4UhI+EOm4mBFJF5G8XqVZuiTop1rcbjejw2N+vxGBTrYUnXlVpTUyw1JRPDiVO/OlfF6X1gOeg+BFy7bduNwJ2ZeQVwZ/e3MeYQs6PYu/XWf7pt83XArd3nW4HXLtcsY8yy6fub/ZLMPNV9/hHzFV2NMYeY/SzZDEBmpvotHhEngBP77ccYsz/63tkfjYhjAN3/p6svZubJzDyemcd79mWMWQJ9xX47cH33+XrgM8sxxxhzUOzG9fZR4OXAxcCjwDuA/wBuA54DfJ+56237JN6iturHfXHZqUwcCtN1LsR+SzL1oW+0mfQPbogdrxIp9l0pSy3JJOrNqnrTer9m/Q9oSZl/U7gAQ7nlhP3SbyurVeejWB6sqKISTh6aEFeLfTsW+7n16iKFxf40foPOmEaw2I1pBIvdmEaw2I1pBIvdmEY4NLPxvWbIN0QVsZbXUNSbnq3tiMIOOYIyd6GY6h6IpJgiT2X1SuSmiOSSDgiVE1O9gBmLQ7niaF0lVV9qNl6ti1cdTpG/UqJOU3U+qv6qYVSRmwLPxhvTOBa7MY1gsRvTCBa7MY1gsRvTCBa7MY1wiFxvquLizUMRzTBV/qlUOTuUv6PqT/qnBLUdypu0KW3ce1AFg7q34azeNxXkU3s+6/vLQIxHSt9bXZaVP2xU79dADO9MOFr1Gnz1GEdx/qTOYFn2ZNebMY1jsRvTCBa7MY1gsRvTCBa7MY1weGbj++RvEpPqw4m4jomllWYq7VDRnxrCgUi1pFZW6pvPanDe4u3xy7rBEHmYJmNhyLRHpIaaVBeBJAMRyDMTS1uNi2M2FcdsPKzPgTOTnrFciyfIAYjiHEkRzKWcLp6NN6ZxLHZjGsFiN6YRLHZjGsFiN6YRLHZjGmE3yz/dArwGOJ2ZL+i23Qy8Gfhx97WbMvNzO3YmXG8D4fGa1evIlHUGImBhELXPbpK1O2lQ9DcT18yRsCOFyytFkM9MBPnExmJXWZ5RQRVqJRMxxiPhVtwsxlhFmahTcSxCg4S7NKaL/VfKs1muZrNDX3otIeWyK84fZUh1DuT+XG8fAq5dsP29mXlV929HoRtj1suOYs/Mu4AdF200xhxu9vOb/YaIuC8ibomIZy3NImPMgdBX7O8Hng9cBZwC3l19MSJORMTdEXF3z76MMUugl9gz89HMnGbmDPgAcLX47snMPJ6Zx/saaYzZP73EHhHHtvz5OuCB5ZhjjDkoduN6+yjwcuBi4FHgHd3fVzH3JzwMvCUzT+3YWURG4U3Inp6hsi/VXI+VpgBGG4tbnWwKA3sGFQ7Pr8umT4iKPfobF5FyANNf1WXqkFVBamdE9NqRM6JBcczOzERh6dZS4Xf98swxqEckZsJlNyj6U2kDi+ZmwvW28hBXi313WOzbsNjP7aqH2P0GnTGNYLEb0wgWuzGNYLEb0wgWuzGNcGgSToocf3WOQhEZ1ndxovGongLd7JFfUSXFlKs4KX9C1NfoYeHWUFGAm/KaX49Hv5yYPTNpiuWThiIKsEwsKczYEMuDnRVZQqP38lWLUcdMOq88G29M21jsxjSCxW5MI1jsxjSCxW5MI1jsxjTCoXG9SRdV4bWogmoARN5IRufVbq3Jr8R4FP2F8KqkCPzgjEiUKIZKLBvGuCjbVJ6fZ4hr/pPCyXO2rne0CApRzclbj/LY1Z63GuG1HQ5rQ6Yicadcj04c60FxrNVQVblKE7vejGkei92YRrDYjWkEi92YRrDYjWmEQzMbL2I7oEjpk2qKdiSm4ycikETMge49lAHYEGV1PE7P0BRgtHhMYiJm93dYuKjsShg5LcrU6k9qfNV4RJEuDGB0dvF+qwn8kepNeEnO9tZSZb/w1hRBMkl6Nt6Y1rHYjWkEi92YRrDYjWkEi92YRrDYjWmE3Sz/dBnwYeAS5u/Zn8zM90XERcDHgcuZLwH1+sz82Q5tLdXPNxDBM3LBj9554SpDRJmyQy1bo1x2auWUol5s1p2Njwp3klgRZih2fLpRuPPUPqv96knl0hWLt8hDJuO1jorCJ+uirDzIwpBRMY6Tfa4IMwHenplXAi8F3hoRVwI3Andm5hXAnd3fxphDyo5iz8xTmfn17vPjwIPApcB1wK3d124FXntANhpjlsCefrNHxOXAi4GvAJdsWbn1R8wf840xhxT1E+QcIuIC4JPA2zLzsYinfxZkZla/xyPiBHBiv4YaY/bHru7sETFmLvSPZOanus2PRsSxrvwYcHpR3cw8mZnHM/P4Mgw2xvRjR7HH/Bb+QeDBzHzPlqLbgeu7z9cDn1m+ecaYZbEb19s1wJeB+3k64Oom5r/bbwOeA3yfuevtpzu0lZXrpVqPHmDWwzWhfTziGjeoGx3NFicum4zqGKrRpPahTVTYG3VCsxD16gEWvqZZP59RiKjDLH4hDoR/LcVhyfIkAHUiDIo2Z7P6F+xQ+F915KNKOChy1xWtznpGI1autx1/s2fmf1Er5097WWOMWTl+g86YRrDYjWkEi92YRrDYjWkEi92YRlh9wslqXl95VqoEkUeFa0It/7RROyEmT4iKlRdNVJGJI8U+b4iysyI67Gixa2LVIsYiwk5Fval608I7KDxedZZKkMd6KGys3HkDMb6TIsEp7LAsV5HsE4AnhdOuSpg5Vf7oyggv/2RM81jsxjSCxW5MI1jsxjSCxW5MI1jsxjTCoXG9DYUZldNCJTyciSivGNY+o9lEuEiqiDhhu0qxWSYaBAYiWm42qKPeBoPFkXlyvzhPlP1SlAnGxbERiS8Hw9pGNY7TIhqx61CU7Z2xiKZMYaRYaq/OnDoTPt3KDLvejDEWuzGNYLEb0wgWuzGNYLEb0wi7TiW9NIpZyT4+gekRMeMugkXUbLY2pJgCFR4N6ewQk62zDZFXTZg/G1SNCkPOEw2KIBMZvLRZ9PcMccweq5vTud/qGfco0uvFk/WpPxMHZlONo7h1jkUg0mYR1aKyKPbRke/sxjSCxW5MI1jsxjSCxW5MI1jsxjSCxW5MI+xm+afLgA8zX5I5gZOZ+b6IuBl4M/Dj7qs3ZebndmhLhYwoKxdvX/y+/1OFypQSdfWrWlQ96UWLVG91cMdAuIaqJYPGYqg2VUTOqO5rKFyHtausXiJpIMYjVUBLCBuLgyNMJ4b1eMS09qHNhCc7hP1ZniXa4Vi213f5J+bj8vbM/HpEXAjcExF3dGXvzcx39bLIGLNSdrPW2yngVPf58Yh4ELj0oA0zxiyXPf1mj4jLgRczX8EV4IaIuC8ibomIZy3bOGPM8ti12CPiAuCTwNsy8zHg/cDzgauY3/nfXdQ7ERF3R8Td+zfXGNOXXWWqiYgx8Fng85n5ngXllwOfzcwX7NCOJ+i24Am6c/EE3XaWO0G34509IgL4IPDgVqFHxLEtX3sd8EAvy4wxK2E3rrdrgC8D9/P0ojM3AW9k/gifwMPAW7rJPNVW2VmIO3tVTaYeE4Fc8nYropPKC7e8TQgzst6BafbLnVbdwWVrRWQY6OhB9WA1KMrEykp67MVSU+pYRxWo2LcvdaxVm32eQpU0e+SgW33CyarMYj8Hi30bFvu5OOGkMabCYjemESx2YxrBYjemESx2Yxph9bPxxeWlmjUFyH7vFtSM6mtcma+R+oUVhUwaOKrdAqmWaxJeiD75JtUZUL/wAYNqOSxgNltcbyTGcKIsOSLsOCOnwRdu3fuRfArhNZIvBfU5ifu9NObZeGMax2I3phEsdmMawWI3phEsdmMawWI3phEOTSBMr/bq0GhSBHAwEi4N4XqLIhBmMKl3a6oD2mtUPeWRKYI4Bk+I5kTgx1QEmaicZuUwiqAbnhRlfTl/8eb4ZV0le7q8+g2ICNZxIIwxpg8WuzGNYLEb0wgWuzGNYLEb0wgWuzGNcGhcb/1SOPeppcu002Vxf0MRQ6W8ayHMlznSekVe1ZaokVr+CPdtsSZUBFiP9pQHTR2Wmdi3gajZJ0W5wq43YxrHYjemESx2YxrBYjemESx2YxphN8s/HQXuYr4i3wj4RGa+IyKeC3wM+F3gHuAvM1Otw6IDYfTKg0Ud0ZlauWNY9zUWS5ZsVlPkYggH59XtzUQAjbwMnxFjNV7cplyEUSUAHPSJxgCqfesZGDQUU+QzUW9Q9DeV54coEn1NZSCMWPSxWDxTpPhjqnIK7mM2/gzwisx8EfO13a6NiJcC7wTem5l/CPwMeNMu2jLGrIkdxZ5zftH9Oe7+JfAK4BPd9luB1x6EgcaY5bCr3+wRMYyIe4HTwB3Ad4GfZ+ZTzx8/BC49EAuNMUthV2LPzGlmXgU8G7ga+KPddhARJyLi7oi4u5+JxphlsKfZ+Mz8OfAl4I+BZ0b8f+6WZwOPFHVOZubxzDy+H0ONMftjR7FHxO9FxDO7z+cBrwQeZC76P+++dj3wmQOy0RizBHbjensh8wm4IfOLw22Z+Q8R8TzmrreLgP8G/iJTZn7bIQddz7xfK2lth77U0lUr2+OdWj0IQ1Z5zNR9qf9iTitjhSdk5Xo7NFFvFvu2ev2t2XuLFvvBcwjE7jfojGkEi92YRrDYjWkEi92YRrDYjWkEFadzEPwE+H73+eLu747lTknuobVtdvToq6fp26rt246Fre69yh7sONBjts2Otc24L+e47H+odmvHH1QFK3W9ndNxxN2H4a0622E7WrHDj/HGNILFbkwjrFPsJ9fY91Zsx7nYjnP5rbFjbb/ZjTGrxY/xxjTCWsQeEddGxP9GxEMRceM6bOjseDgi7o+Ie1eZXCMibomI0xHxwJZtF0XEHRHxne7/Z63Jjpsj4pFuTO6NiFevwI7LIuJLEfGtiPhmRPx1t32lYyLsWOmYRMTRiPhqRHyjs+Pvu+3PjYivdLr5eERs7KnhzFzpP+ahst8FngdsAN8Arly1HZ0tDwMXr6HflwEvAR7Ysu2fgBu7zzcC71yTHTcDf7Pi8TgGvKT7fCHwbeDKVY+JsGOlY8I8Ru6C7vMY+ArwUuA24A3d9n8G/mov7a7jzn418FBmfi/nqac/Bly3BjvWRmbeBfx02+brmOcNgBUl8CzsWDmZeSozv959fpx5cpRLWfGYCDtWSs5ZepLXdYj9UuAHW/5eZ7LKBL4QEfdExIk12fAUl2Tmqe7zj4BL1mjLDRFxX/eYf+A/J7YSEZcDL2Z+N1vbmGyzA1Y8JgeR5LX1CbprMvMlwJ8Bb42Il63bIJhf2Vl+jo3d8n7g+czXCDgFvHtVHUfEBcAngbdl5mNby1Y5JgvsWPmY5D6SvFasQ+yPAJdt+btMVnnQZOYj3f+ngU8zH9R18WhEHAPo/j+9DiMy89HuRJsBH2BFYxIRY+YC+0hmfqrbvPIxWWTHusak6/vn7DHJa8U6xP414IpuZnEDeANw+6qNiIjzI+LCpz4DrwIe0LUOlNuZJ+6ENSbwfEpcHa9jBWMSEQF8EHgwM9+zpWilY1LZseoxObAkr6uaYdw22/hq5jOd3wX+dk02PI+5J+AbwDdXaQfwUeaPg5vMf3u9ifmaeXcC3wG+CFy0Jjv+FbgfuI+52I6twI5rmD+i3wfc2/179arHRNix0jEBXsg8iet9zC8sf7flnP0q8BDw78CRvbTrN+iMaYTWJ+iMaQaL3ZhGsNiNaQSL3ZhGsNiNaQSL3ZhGsNiNaQSL3ZhG+D/Ye5fbywIMtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_image[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84c25150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5002174]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "posterior_prob_dis = D(generated_image)\n",
    "print(posterior_prob_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94d0d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False ,label_smoothing=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "932ececa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dis_loss(real_img , fake_img_preds):\n",
    "    real_img_labels = tf.ones_like(real_img)\n",
    "    fake_img_labels = tf.zeros_like(fake_img_preds)\n",
    "    \n",
    "    real_img_loss = bce_loss(y_true=real_img,y_pred=real_img_labels)\n",
    "    fake_img_pred_loss = bce_loss(y_true=fake_img_preds , y_pred=fake_img_labels)\n",
    "    \n",
    "    total_loss = real_img_loss + fake_img_pred_loss\n",
    "    return loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85f4931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_loss(fake_img_preds):\n",
    "    fake_img_labels = tf.zeros_like(fake_img_preds)\n",
    "    return bce_loss(y_true=fake_img_preds ,y_pred = fake_img_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b30167c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizers = tf.keras.optimizers.Adam(learning_rate=0.008 ,beta_1 = 0.3)\n",
    "G_optimizers = tf.keras.optimizers.Adam(learning_rate=0.004 , beta_1 = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47b25dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir_path = os.path.join(root_dir,\"Checkpoint\")\n",
    "# Gan_checkpoint_dir = os.mkdir(ckpt_dir_path)\n",
    "Gan_checkpoint_dir_prefix =os.path.join(ckpt_dir_path,\"ckpt\")\n",
    "GAN_ckeckpoint = tf.train.Checkpoint(optimizer = [D_optimizers,G_optimizers] , model = [D,G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "921fdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise = tf.random.normal(shape=(1,100),seed = 32,name = \"Random Noise\")\n",
    "epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15caa7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def time_step(real_img):\n",
    "    G.trainable = False\n",
    "    noise = tf.random.normal(shape=(batch_size,random_noise))\n",
    "    Fake_img_gen_mini_batch = G(noise,trainable = False)\n",
    "    \n",
    "    D.trainable = True\n",
    "    \n",
    "    with tf.GradientTape() as disc_tape ,tf.GradientTape() as gen_tape:\n",
    "        real_img_preds = D(real_img ,training =True)\n",
    "        fake_img_preds = D(Fake_img_gen_mini_batch ,training = True)\n",
    "        \n",
    "        D_loss = Dis_loss(real_img_preds , fake_img_preds)\n",
    "        gradient_of_disc = disc_tape.gradient(D_loss ,D.trainable_weights)\n",
    "        D_optimizers.apply_gradients(zip(gradient_of_disc,D.trainable_variables))\n",
    "        \n",
    "        G.trainable = True\n",
    "        D.trainable = False\n",
    "        \n",
    "        noise = tf.random.normal(shape = (batch_size,random_noise))\n",
    "        Fake_img_gen_mini_batch = G(noise,training = True)\n",
    "        \n",
    "        Gen_loss = G_loss(fake_img_preds= Fake_img_gen_mini_batch , training =True)\n",
    "        gradient_of_gen = gen_tape.gradient(Gen_loss , G.trainable_variables)\n",
    "        G_optimizers.apply_gradients(zip(Gen_loss ,G.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0653419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0099\n"
     ]
    }
   ],
   "source": [
    "num= 99\n",
    "print(\"{:04}\".format(num))\n",
    "%04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
